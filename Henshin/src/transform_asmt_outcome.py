'''
Transform generated assessment outcome data into landing zone format - [Outcome]
Landing Zone Format: https://confluence.wgenhq.net/display/CS/New+UDL
'''
import os.path
import csv
from column_headers import COLUMN_MAP_INFO

DATAFILE_PATH = str(os.path.split(os.path.abspath(os.path.dirname(__file__)))[0])
DEFAULT_FACT_ASMT_OUTCOME_FILE = os.path.join(DATAFILE_PATH, 'datafiles', 'fact_asmt_outcome.csv')
DEFAULT_LANDING_ZONE_OUTCOME_FILE = os.path.join(DATAFILE_PATH, 'datafiles', 'METADATA_ASMT_ID_{0}.csv')


def transform_to_realdata(source_file, asmt_id_list, fact_asmt_outcome_file_pattern):
    '''
    Function to transform data from fact_asmt_outcome.csv into landing zone format
    @param source_file: file name of input source file. It can be fact_asmt_outcome.csv generated by data generation process
    @param asmt_id_list: all asmt_ids. Each asmt_id maps to one csv file to be generated
    @param fact_asmt_outcome_file_pattern: output file path pattern
    '''
    # check if file exists or not, file type, etc
    is_valid_file = validate_file(source_file)
    # TODO: if is_valid_file is False, need to delete all METADATA files?

    # valid file
    if is_valid_file:
        # check if all required columns in target_columns has corresponding column in source_file
        # If it has, get list of target_columns, and corresponding source_columns. Otherwise, throw exception
        target_columns, source_columns = get_source_and_target_columns(source_file)
        if len(target_columns) > 0 and len(target_columns) == len(source_columns):
            # start transformation process
            transform_file_process(source_file, asmt_id_list, target_columns, source_columns, fact_asmt_outcome_file_pattern)
        else:
            print("Error occurs to mapping columns from source file ", source_file)


def validate_file(file_name):
    '''
    Validate the input file.
    Check if the input file_name exists and if it is a file
    '''
    isValid = os.path.exists(file_name) and os.path.isfile(file_name)
    if isValid is False:
        print("invalid file ", file_name)
    return isValid


def get_source_and_target_columns(source_file):
    '''
    Generate column names in landing zone format, and their mapping column names in source file.
    The mapping between columns in landing zone format and in source file is defined
    as COLUMN_MAP_INFO in column_headers.csv.
    If required columns in landing zone format are missing in source file, exception occurs.
    @param source_file: file name of input source file. It can be fact_asmt_outcome.csv generated by data generation process
    '''
    # flatten the required columns
    target_columns_list = []
    source_columns_list = []

    missing_columns_list = []
    # read headers from source_file
    with open(source_file, newline='') as file:
        reader = csv.reader(file, delimiter=',', quoting=csv.QUOTE_NONE)
        column_names_in_source_file = next(reader)

    # loop column_header_info, create target_columns_list, column_names_in_source_file
    for source_and_target_column_mapping in COLUMN_MAP_INFO:
        target_column_name = source_and_target_column_mapping[0]
        source_column_name = source_and_target_column_mapping[1]

        if source_column_name not in column_names_in_source_file:
            # add one missing column
            missing_columns_list.append(source_column_name)

        target_columns_list.append(target_column_name)
        source_columns_list.append(source_column_name)

    # no missing columns
    if len(missing_columns_list) == 0:
        return target_columns_list, source_columns_list

    else:
        print("This column is missing -- ", missing_columns_list, "in file ", source_file)
        raise ValueError


def transform_file_process(source_file, asmt_id_list, target_columns, source_columns, fact_asmt_outcome_file_pattern):
    '''
    Transformation process
    @param source_file:  file name of input source file. It can be fact_asmt_outcome.csv generated by data generation process
    @param asmt_id_list: list of asmt_id which plays as a filter to select rows from source_file
    @param target_columns: header of real data file
    @param source_columns: mapping column names target_columns in source_file
    @param fact_asmt_outcome_file_pattern: real data file name pattern
    '''
    print("Start to transform ", source_file, "into landing zone format...")
    # filter all rows which asmt_id in asmt_id_list
    # transformed_rows_dict is a dictionary. Key is the asmt_id in asmt_id_list, and values are list of rows in source file
    transformed_rows_dict = filter_by_asmt_id(source_file, asmt_id_list, source_columns)

    # create target files
    for asmt_id, rows in transformed_rows_dict.items():
        # output file name format
        output_file = fact_asmt_outcome_file_pattern.format(str(asmt_id))
        with open(output_file, 'w', newline='') as csvfile:
            output_writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)
            # write headers
            output_writer.writerow(target_columns)
            # write rows
            output_writer.writerows(rows)
    print("Done!")


def filter_by_asmt_id(source_file, asmt_id_list, source_columns):
    '''
    Function to filter rows in source_file
    Read source_file, generate a dictionary which
    use each asmt_id in asmt_id_list as the key, corresponding rows with of columns in source_columns as value
    '''
    # initialize dictionary
    asmt_dict = {}
    for asmt_id in asmt_id_list:
        asmt_dict[str(asmt_id)] = []

    with open(source_file, newline='') as file:
        reader = csv.DictReader(file, delimiter=',', quoting=csv.QUOTE_NONE)
        for row in reader:
            asmt_guid = row['asmt_rec_id']
            if asmt_guid in asmt_dict.keys():
                # pick values only in source_columns
                new_row = [row[source_column] for source_column in source_columns]
                asmt_dict[str(asmt_guid)].append(new_row)
    return asmt_dict


if __name__ == '__main__':
    print(os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__))))
    source_file = DEFAULT_FACT_ASMT_OUTCOME_FILE
    target_file_path = DEFAULT_LANDING_ZONE_OUTCOME_FILE
    asmt_id_list = [i for i in range(20, 35)]
    transform_to_realdata(source_file, asmt_id_list, target_file_path)
