###
# udl configuration
###

common:
  '[app]':
    celery:
        root: udl2.celery
        broker: amqp://guest@localhost//    # this is the url to message broker. Currently it is located on localhost for rabbitmq
        backend: amqp://guest@localhost//   # this is the url to task results for each request. Currently it is located on localhost for rabbitmq
        include: 
            - udl2.W_file_arrived
            - udl2.W_file_decrypter
            - udl2.W_file_expander
            - udl2.W_simple_file_validator
            - udl2.W_file_splitter
            - udl2.W_parallel_csv_load
            - udl2.W_load_csv_to_staging
            - udl2.W_file_content_validator
            - udl2.W_load_json_to_integration
            - udl2.W_load_to_integration_table
            - udl2.W_load_from_integration_to_star
            - udl2.W_post_etl
            - udl2.W_report_error_or_success
            - udl2.W_all_done
            - benchmarking.run_benchmarks
    celery_defaults: 
        CELERY_DEFAULT_QUEUE: celery        # default celery queue name for celery internal tasks
        CELERY_DEFAULT_EXCHANGE: direct     # default celery exchange name, and exchange type
        CELERY_DEFAULT_ROUTING_KEY: celery  # default celery routing key for tasks
        CELERY_TASK_RESULT_EXPIRES: 10      # TTL for results
        CELERY_CONCURRENCY: 10              # number of available workers processes
        CELERY_SEND_EVENTS: True            # send events for monitor
    rabbitmq:                               # rabbitmq server for local testing if we requires to bring up a rabbitmq server for UDL2 celery tasks on this machine. It will be ignore by celery if there are global rabbitmq-server
        RABBITMQ_SERVER_PATH: 
            - /opt/local/sbin/rabbitmq-server
            - /usr/local/sbin/rabbitmq-server       # where the rabbitmq-server is located, we list all possible locations in your system. 
    file_splitter:                          # Options for file_splitter
        row_limit: 10000                    # default row number for split files
        parts: 1                            # default parts of files
        output_path: .                      # where the newly generated split file located
        keep_headers: True                  # preserve csv header for importing
    work_zone_sub_dir:
        arrived: arrived
        decrypted: decrypted
        expanded: expanded
        subfiles: subfiles
        history: history
    logging:        # log location. this should be in the long run as file locations or more sophisticated logging system
        level: INFO
        debug: FALSE
        audit: /opt/edware/log/udl2.audit.log  # for status log for everything
        error: /opt/edware/log/udl2.error.log  # for error message and exceptions,
    multi_tenant:
        active: False
        default_tenant: edware
    quiet_mode: False
    passphrase: sbac udl2
    tenant_position: -4
    search_wait_time: 10


qa:
  '[app]':
    zones:                                              # zones for where the files are uploaded and processed. it may change to other mechanisms, but we uses local file system for the moment.
        landing: /opt/edware/zones/landing/             # this is for where the uploaded files are located, it may be an url in the long run to get data
        arrivals: /opt/edware/zones/landing/arrivals/   # this is where the file arrives.
        work: /opt/edware/zones/landing/work/           # this is the where the file are use for work. this should always be local for speed
        history: /opt/edware/zones/landing/history/     # this is where we store historical info. it may be an url for large file storages such as s3.
    udl2_db:
        csv_schema: udl2  # PostgresQL for UDL2 processing. This is not the target database.
        reference_schema: udl2
        fdw_server: udl2_fdw_server
        staging_schema: udl2
        integration_schema: udl2
        ref_table_name: REF_COLUMN_MAPPING
        batch_table: UDL_BATCH
        db_host: rbtmqudl0.qa.dum.edwdc.net
        db_port: 5432
        db_name: udl2
        db_database: udl2
        db_schema: udl2
        db_user: udl2
        db_pass: udl2abc1234
        db_driver: postgresql
        json_lz_table: LZ_JSON
        csv_lz_table: LZ_CSV
        master_metadata_table: MASTER_METADATA
        # sqlalchemy specific
        echo: False
        max_overflow: 10
        pool_size: 20
    udl2_db_conn:
        url: postgresql://udl2:udl2abc1234@rbtmqudl0.qa.dum.edwdc.net:5432/udl2
        db_schema: udl2
        echo: False
        max_overflow: 10
        pool_size: 20
    target_db_conn:
        edware:
            url: postgresql://edware:edware2013@dbpgudl0.qa.dum.edwdc.net:5432/edware
            db_schema: edware
            echo: False
            max_overflow: 10
            pool_size: 20
            db_database: edware
            db_user: edware
            db_pass: edware2013
        ca:
            url: postgresql://edware:edware2013@dbpgudl0.qa.dum.edwdc.net:5432/edware
            db_schema: edware
            echo: False
            max_overflow: 10
            pool_size: 20
            db_database: edware
            db_user: edware
            db_pass: edware2013
    target_db:
        db_schema: edware
        db_name: edware
        # TBD make sure it is the production setting
        db_host: dbpgudl0.qa.dum.edwdc.net
        db_port: 5432
        db_database: edware
        db_user: edware
        db_pass: edware2013
        db_driver: postgresql
    gpg_home: /home/udl2/.gnupg


development:
  '[app]':
    zones:                                              # zones for where the files are uploaded and processed. it may change to other mechanisms, but we uses local file system for the moment.
        landing: /opt/edware/zones/landing/             # this is for where the uploaded files are located, it may be an url in the long run to get data
        arrivals: /opt/edware/zones/landing/arrivals/   # this is where the file arrives.
        work: /opt/edware/zones/landing/work/           # this is the where the file are use for work. this should always be local for speed
        history: /opt/edware/zones/landing/history/     # this is where we store historical info. it may be an url for large file storages such as s3.
        datafiles: /opt/edware/zones/datafiles/         # this is for storing test sample data files
        tests: /opt/edware/zones/tests/                 # this is for running unit tests.
    udl2_db:
        csv_schema: udl2  # PostgresQL for UDL2 processing. This is not the target database.
        reference_schema: udl2
        fdw_server: udl2_fdw_server
        staging_schema: udl2
        integration_schema: udl2
        ref_table_name: REF_COLUMN_MAPPING
        batch_table: UDL_BATCH
        db_host: localhost
        db_port: 5432
        db_name: udl2
        db_database: udl2
        db_schema: udl2
        db_user: udl2
        db_pass: udl2abc1234
        db_driver: postgresql
        json_lz_table: LZ_JSON
        csv_lz_table: LZ_CSV
        master_metadata_table: MASTER_METADATA
    target_db:
        db_schema: edware
        db_name: edware
        # TBD make sure it is the production setting
        db_host: localhost
        db_port: 5432
        db_database: edware
        db_user: edware
        db_pass: edware2013
        db_driver: postgresql
    udl2_db_conn:
        url: postgresql://udl2:udl2abc1234@localhost:5432/udl2
        db_schema: udl2
        echo: False
        max_overflow: 10
        pool_size: 20
    target_db_conn:
        edware:
            url: postgresql://edware:edware2013@localhost:5432/edware
            db_schema: edware
            echo: False
            max_overflow: 10
            pool_size: 20
            db_database: edware
            db_user: edware
            db_pass: edware2013
        ca:
            url: postgresql://edware:edware2013@localhost:5432/edware
            db_schema: edware
            echo: False
            max_overflow: 10
            pool_size: 20
            db_database: edware
            db_user: edware
            db_pass: edware2013
        func_tests:
            url: postgresql://edware:edware2013@localhost:5432/edware
            db_schema: ftest_test_schema
            echo: False
            max_overflow: 10
            pool_size: 20
            db_database: edware
            db_user: edware
            db_pass: edware2013
    gpg_home: ~/.gnupg